akka {
  loglevel = "ERROR"
  actor.provider = cluster
  actor.warn-about-java-serializer-usage = on
  actor.allow-java-serialization = on
  coordinated-shutdown.exit-jvm = on

  actor {
    serializers {
      catalog-item-added = "it.pagopa.pdnd.interop.uservice.catalogmanagement.model.persistence.serializer.CatalogItemAddedSerializer"
      state = "it.pagopa.pdnd.interop.uservice.catalogmanagement.model.persistence.serializer.StateSerializer"
      akka-projection = "akka.projection.internal.ProjectionSerializer"
    }
    serialization-identifiers {
      "it.pagopa.pdnd.interop.uservice.catalogmanagement.model.persistence.serializer.CatalogItemAddedSerializer" = 100000
      "it.pagopa.pdnd.interop.uservice.catalogmanagement.model.persistence.serializer.StateSerializer" = 200000
      "java.io.serializable" = none
    }
    serialization-bindings {
      "it.pagopa.pdnd.interop.uservice.catalogmanagement.model.persistence.CatalogItemAdded" = catalog-item-added
      "it.pagopa.pdnd.interop.uservice.catalogmanagement.model.persistence.State" = state
      "akka.projection.ProjectionBehavior$Internal$ProjectionManagementCommand" = akka-projection
      "akka.projection.ProjectionBehavior$Internal$CurrentOffset" = akka-projection
    }
  }

  cluster {
    shutdown-after-unsuccessful-join-seed-nodes = 60s
    sharding {
      number-of-shards = 60 //number of nodes * 10
    }
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
  }

  persistence {
    journal.plugin = "akka.persistence.cassandra.journal"
    journal.auto-start-journals = ["akka.persistence.cassandra.journal"]
    snapshot-store.plugin = "akka.persistence.cassandra.snapshot"
    cassandra {
      events-by-tag {
        bucket-size = "Day"
        eventual-consistency-delay = 2s
        flush-interval = 50ms
        pubsub-notification = on
        first-time-bucket = "20200815T00:00"
      }
      query {
        refresh-interval = 2s
      }
      journal.keyspace = "uservice_catalog_management"
      snapshot.keyspace = "uservice_catalog_management_snap"
    }
  }
  seed-nodes = ["akka://pdnd-interop-uservice-catalog-management@127.0.0.1:2552"]
  projection {
    cassandra.offset-store.keyspace = "uservice_catalog_management_proj"
    cassandra.session-config-path = "akka.persistence.cassandra"
    restart-backoff {
      min-backoff = 3s
      max-backoff = 30s
      random-factor = 0.2
      max-restarts = -1
    }

    grouped {
      group-after-envelopes = 20
      group-after-duration = 500 ms
    }

    management {
      operation-timeout = 10 s
      ask-timeout = 3 s
    }
  }

  typed {
    stash-capacity = 200000
  }
}

datastax-java-driver {
  basic {
    contact-points = [${CASSANDRA_HOST}]
    load-balancing-policy.local-datacenter = "dc1"
  }
  advanced {
    reconnect-on-init = true
    auth-provider {
      class = PlainTextAuthProvider
      username = ${CASSANDRA_USER}
      password = ${CASSANDRA_PWD}
    }
  }
}

akka.management {
  cluster.bootstrap {
    contact-point-discovery {
      discovery-method = kubernetes-api
      required-contact-point-nr = ${?REQUIRED_CONTACT_POINT_NR}
    }
  }
}

akka.management {
  health-checks {
    readiness-checks {
      ready = "it.pagopa.pdnd.interop.uservice.catalogmanagement.server.impl.HealthCheck"
    }
    liveness-checks {
      live = "it.pagopa.pdnd.interop.uservice.catalogmanagement.server.impl.LiveCheck"
    }
  }
}

kamon.prometheus {
  embedded-server {
    hostname = 0.0.0.0
  }
}

kamon.instrumentation.akka.http {
  server {
    propagation {
      enabled = yes
      channel = default
    }
  }

  client {
    propagation {
      enabled = yes
      channel = default
    }
  }
}

kamon.instrumentation.akka.http {
  server.metrics {
    enabled = yes
  }
}

kamon.instrumentation.akka.http {
  server {
    tracing {
      enabled = yes
      span-metrics = on
    }
  }

  client {
    tracing {
      enabled = yes
      span-metrics = on
    }
  }
}

uservice-catalog-management {
  idle-timeout = 60 seconds
  number-of-events-before-snapshot = 1000
}
